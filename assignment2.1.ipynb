{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4596e37"
      },
      "source": [
        "# Task\n",
        "Implement the TF-IDF algorithm manually in Python and compare the results with scikit-learn's `CountVectorizer` and `TfidfVectorizer` using the provided corpus. Explain the differences in the scores, particularly for common words, and summarize the findings in a README.md file. The final output should be a Jupyter Notebook (.ipynb) or Python script (.py) and a README.md file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77fd4953"
      },
      "source": [
        "## Define corpus\n",
        "\n",
        "### Subtask:\n",
        "Define the corpus given in the problem description.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b65268fa"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires defining a corpus as a list of strings. This can be achieved by creating a Python list and adding the specified sentences as elements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cc3710a"
      },
      "source": [
        "corpus = [\n",
        "    \"This is the first document.\",\n",
        "    \"This document is the second document.\",\n",
        "    \"And this is the third one.\",\n",
        "    \"Is this the first document?\",\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f49ad674"
      },
      "source": [
        "## Manual tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Implement a function to calculate Term Frequency (TF).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09c43a78"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the TF calculation function as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84f8a7a0",
        "outputId": "847ab629-01a0-49eb-9d11-c1c138f096ae"
      },
      "source": [
        "import re\n",
        "\n",
        "def calculate_tf(document):\n",
        "  \"\"\"Calculates the Term Frequency (TF) for each word in a document.\n",
        "\n",
        "  Args:\n",
        "    document: A string representing the document.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary where keys are words and values are their corresponding TF scores.\n",
        "  \"\"\"\n",
        "  # Convert to lowercase and split into words\n",
        "  words = re.findall(r'\\b\\w+\\b', document.lower())\n",
        "  word_counts = {}\n",
        "  for word in words:\n",
        "    word_counts[word] = word_counts.get(word, 0) + 1\n",
        "\n",
        "  total_words = len(words)\n",
        "  tf_scores = {}\n",
        "  for word, count in word_counts.items():\n",
        "    tf_scores[word] = count / total_words\n",
        "\n",
        "  return tf_scores\n",
        "\n",
        "# Test the function with the first document from the corpus\n",
        "first_document = corpus[0]\n",
        "tf_scores_first_doc = calculate_tf(first_document)\n",
        "print(tf_scores_first_doc)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 0.2, 'is': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed253c2"
      },
      "source": [
        "## Manual tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Implement a function to calculate Inverse Document Frequency (IDF).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f75f0dc"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `calculate_idf` function according to the instructions, including iterating through the corpus, counting document frequencies, calculating IDF scores, and testing the function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e0267c0",
        "outputId": "91592f44-be63-4259-eec2-159605a14a75"
      },
      "source": [
        "import math\n",
        "import re\n",
        "\n",
        "def calculate_idf(corpus):\n",
        "  \"\"\"Calculates the Inverse Document Frequency (IDF) for each word in a corpus.\n",
        "\n",
        "  Args:\n",
        "    corpus: A list of strings, where each string is a document.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary where keys are words and values are their corresponding IDF scores.\n",
        "  \"\"\"\n",
        "  document_frequency = {}\n",
        "  total_documents = len(corpus)\n",
        "\n",
        "  for document in corpus:\n",
        "    # Convert to lowercase and find unique words in the document\n",
        "    words = set(re.findall(r'\\b\\w+\\b', document.lower()))\n",
        "    for word in words:\n",
        "      document_frequency[word] = document_frequency.get(word, 0) + 1\n",
        "\n",
        "  idf_scores = {}\n",
        "  for word, doc_count in document_frequency.items():\n",
        "    idf_scores[word] = math.log(total_documents / doc_count)\n",
        "\n",
        "  return idf_scores\n",
        "\n",
        "# Test the function with the defined corpus\n",
        "idf_scores_corpus = calculate_idf(corpus)\n",
        "print(idf_scores_corpus)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 0.0, 'is': 0.0, 'document': 0.28768207245178085, 'the': 0.0, 'first': 0.6931471805599453, 'second': 1.3862943611198906, 'and': 1.3862943611198906, 'third': 1.3862943611198906, 'one': 1.3862943611198906}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17de262f"
      },
      "source": [
        "## Manual tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Implement a function to calculate TF-IDF using the TF and IDF functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caf5ac68"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `calculate_tfidf` function, calculate TF-IDF for the first document, and print the results as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40bdfb0b",
        "outputId": "7269bf48-507a-429b-e908-0190905df650"
      },
      "source": [
        "def calculate_tfidf(tf_scores, idf_scores):\n",
        "  \"\"\"Calculates the TF-IDF scores for words in a document.\n",
        "\n",
        "  Args:\n",
        "    tf_scores: A dictionary of TF scores for a document.\n",
        "    idf_scores: A dictionary of IDF scores for the corpus.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary where keys are words and values are their TF-IDF scores.\n",
        "  \"\"\"\n",
        "  tfidf_scores = {}\n",
        "  for word, tf in tf_scores.items():\n",
        "    idf = idf_scores.get(word, 0)  # Get IDF score, default to 0 if word not in IDF scores\n",
        "    tfidf_scores[word] = tf * idf\n",
        "  return tfidf_scores\n",
        "\n",
        "# Calculate TF-IDF scores for the first document\n",
        "tfidf_scores_first_doc = calculate_tfidf(tf_scores_first_doc, idf_scores_corpus)\n",
        "\n",
        "# Print the resulting TF-IDF scores\n",
        "print(tfidf_scores_first_doc)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 0.0, 'is': 0.0, 'the': 0.0, 'first': 0.13862943611198905, 'document': 0.05753641449035617}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26b6bb5b"
      },
      "source": [
        "## Manual tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Calculate the manual TF-IDF scores for the corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9567cca5"
      },
      "source": [
        "**Reasoning**:\n",
        "Iterate through each document in the corpus, calculate its TF and TF-IDF scores, and store the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e856f1",
        "outputId": "01b8bf1f-245a-4a95-83a2-359f30e9e393"
      },
      "source": [
        "tfidf_scores_corpus_manual = []\n",
        "\n",
        "for document in corpus:\n",
        "  tf_scores = calculate_tf(document)\n",
        "  tfidf_scores = calculate_tfidf(tf_scores, idf_scores_corpus)\n",
        "  tfidf_scores_corpus_manual.append(tfidf_scores)\n",
        "\n",
        "print(tfidf_scores_corpus_manual)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'this': 0.0, 'is': 0.0, 'the': 0.0, 'first': 0.13862943611198905, 'document': 0.05753641449035617}, {'this': 0.0, 'document': 0.09589402415059362, 'is': 0.0, 'the': 0.0, 'second': 0.23104906018664842}, {'and': 0.23104906018664842, 'this': 0.0, 'is': 0.0, 'the': 0.0, 'third': 0.23104906018664842, 'one': 0.23104906018664842}, {'is': 0.0, 'this': 0.0, 'the': 0.0, 'first': 0.13862943611198905, 'document': 0.05753641449035617}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34eba856"
      },
      "source": [
        "## Scikit-learn tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Use `CountVectorizer` to get the term frequencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40bc76ab"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary class and instantiate it to calculate the term frequencies using CountVectorizer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eec7c17",
        "outputId": "9ce68d84-2dcc-43f4-85df-5dbf0792ef4b"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Instantiate CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to get the term frequencies\n",
        "count_matrix = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (words)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display the count matrix and feature names\n",
        "print(\"Count Matrix:\\n\", count_matrix.toarray())\n",
        "print(\"\\nFeature Names:\", feature_names)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count Matrix:\n",
            " [[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]]\n",
            "\n",
            "Feature Names: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b67161a0"
      },
      "source": [
        "## Scikit-learn tf-idf implementation\n",
        "\n",
        "### Subtask:\n",
        "Use `TfidfVectorizer` to get the TF-IDF scores.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6918a38"
      },
      "source": [
        "**Reasoning**:\n",
        "Import TfidfVectorizer, instantiate it, fit and transform the corpus, get feature names, and display the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee1ab18f",
        "outputId": "c2991756-3b5b-45be-bc13-8ba508e6e77e"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Instantiate TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the corpus to get the TF-IDF scores\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Get the feature names (words)\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Display the TF-IDF matrix and feature names\n",
        "print(\"TF-IDF Matrix:\\n\", tfidf_matrix.toarray())\n",
        "print(\"\\nFeature Names:\", tfidf_feature_names)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Matrix:\n",
            " [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]\n",
            " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
            "  0.28108867 0.         0.28108867]\n",
            " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
            "  0.26710379 0.51184851 0.26710379]\n",
            " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]]\n",
            "\n",
            "Feature Names: ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c93730ca"
      },
      "source": [
        "## Comparison and analysis\n",
        "\n",
        "### Subtask:\n",
        "Compare the results from the manual implementation and scikit-learn's implementations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c812b9f"
      },
      "source": [
        "**Reasoning**:\n",
        "Compare the manual and scikit-learn TF and TF-IDF results and explain the differences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a90e832b",
        "outputId": "092487e1-b297-4f18-fffa-c926c1bf0ed7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Compare manual TF-IDF with scikit-learn TF-IDF\n",
        "print(\"--- TF-IDF Comparison ---\")\n",
        "print(\"Manual TF-IDF Scores (first document):\", tfidf_scores_corpus_manual[0])\n",
        "print(\"Scikit-learn TF-IDF Scores (first document):\")\n",
        "\n",
        "# Align scikit-learn TF-IDF scores with manual scores based on feature names\n",
        "tfidf_sklearn_first_doc = {}\n",
        "sklearn_tfidf_array = tfidf_matrix.toarray()[0]\n",
        "for i, word in enumerate(tfidf_feature_names):\n",
        "    tfidf_sklearn_first_doc[word] = sklearn_tfidf_array[i]\n",
        "\n",
        "print(tfidf_sklearn_first_doc)\n",
        "\n",
        "# 2. Compare manual TF with scikit-learn TF\n",
        "print(\"\\n--- TF Comparison ---\")\n",
        "print(\"Manual TF Scores (first document):\", tf_scores_first_doc)\n",
        "print(\"Scikit-learn TF Scores (first document):\")\n",
        "\n",
        "# Align scikit-learn TF scores with manual scores based on feature names\n",
        "tf_sklearn_first_doc = {}\n",
        "sklearn_count_array = count_matrix.toarray()[0]\n",
        "for i, word in enumerate(feature_names):\n",
        "    # Calculate TF from count matrix\n",
        "    total_words_first_doc = sum(count_matrix.toarray()[0])\n",
        "    tf_sklearn_first_doc[word] = sklearn_count_array[i] / total_words_first_doc if total_words_first_doc > 0 else 0\n",
        "\n",
        "print(tf_sklearn_first_doc)\n",
        "\n",
        "\n",
        "# 3. Explanation of differences\n",
        "print(\"\\n--- Explanation of Differences ---\")\n",
        "print(\"Comparing the manual and scikit-learn implementations:\")\n",
        "\n",
        "print(\"\\nTF Scores:\")\n",
        "print(\"Manual TF calculation divides the word count by the total number of words in the document.\")\n",
        "print(\"Scikit-learn's CountVectorizer provides raw counts. To get TF from scikit-learn's CountVectorizer, we also need to divide the word count by the total number of words in the document.\")\n",
        "print(\"When calculated correctly, the TF scores should be very similar between manual and scikit-learn implementations, assuming the same tokenization.\")\n",
        "print(\"Any minor differences might arise from slight variations in tokenization or handling of punctuation/case by the manual regex compared to CountVectorizer's default settings.\")\n",
        "\n",
        "print(\"\\nTF-IDF Scores:\")\n",
        "print(\"The core difference lies in the IDF calculation.\")\n",
        "print(\"Manual IDF uses the formula: log(Total Documents / Document Frequency).\")\n",
        "print(\"Scikit-learn's TfidfVectorizer uses a slightly different formula for IDF: log((Total Documents + 1) / (Document Frequency + 1)) + 1. It also applies L2 normalization to the resulting TF-IDF vectors.\")\n",
        "print(\"This difference in the IDF formula, particularly the '+1' smoothing terms and the final '+1', is the primary reason for the differences in the final TF-IDF scores, especially for words that appear in all documents (where manual IDF is 0, but scikit-learn's is not).\")\n",
        "print(\"For common words that appear in all documents ('this', 'is', 'the'), the manual TF-IDF score is 0 because their IDF is 0. Scikit-learn's TfidfVectorizer assigns a non-zero (though small) TF-IDF score due to the smoothing term in its IDF formula.\")\n",
        "print(\"The L2 normalization in scikit-learn also scales the scores, making direct comparison of raw values challenging without reproducing the normalization manually.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- TF-IDF Comparison ---\n",
            "Manual TF-IDF Scores (first document): {'this': 0.0, 'is': 0.0, 'the': 0.0, 'first': 0.13862943611198905, 'document': 0.05753641449035617}\n",
            "Scikit-learn TF-IDF Scores (first document):\n",
            "{'and': np.float64(0.0), 'document': np.float64(0.46979138557992045), 'first': np.float64(0.5802858236844359), 'is': np.float64(0.38408524091481483), 'one': np.float64(0.0), 'second': np.float64(0.0), 'the': np.float64(0.38408524091481483), 'third': np.float64(0.0), 'this': np.float64(0.38408524091481483)}\n",
            "\n",
            "--- TF Comparison ---\n",
            "Manual TF Scores (first document): {'this': 0.2, 'is': 0.2, 'the': 0.2, 'first': 0.2, 'document': 0.2}\n",
            "Scikit-learn TF Scores (first document):\n",
            "{'and': np.float64(0.0), 'document': np.float64(0.2), 'first': np.float64(0.2), 'is': np.float64(0.2), 'one': np.float64(0.0), 'second': np.float64(0.0), 'the': np.float64(0.2), 'third': np.float64(0.0), 'this': np.float64(0.2)}\n",
            "\n",
            "--- Explanation of Differences ---\n",
            "Comparing the manual and scikit-learn implementations:\n",
            "\n",
            "TF Scores:\n",
            "Manual TF calculation divides the word count by the total number of words in the document.\n",
            "Scikit-learn's CountVectorizer provides raw counts. To get TF from scikit-learn's CountVectorizer, we also need to divide the word count by the total number of words in the document.\n",
            "When calculated correctly, the TF scores should be very similar between manual and scikit-learn implementations, assuming the same tokenization.\n",
            "Any minor differences might arise from slight variations in tokenization or handling of punctuation/case by the manual regex compared to CountVectorizer's default settings.\n",
            "\n",
            "TF-IDF Scores:\n",
            "The core difference lies in the IDF calculation.\n",
            "Manual IDF uses the formula: log(Total Documents / Document Frequency).\n",
            "Scikit-learn's TfidfVectorizer uses a slightly different formula for IDF: log((Total Documents + 1) / (Document Frequency + 1)) + 1. It also applies L2 normalization to the resulting TF-IDF vectors.\n",
            "This difference in the IDF formula, particularly the '+1' smoothing terms and the final '+1', is the primary reason for the differences in the final TF-IDF scores, especially for words that appear in all documents (where manual IDF is 0, but scikit-learn's is not).\n",
            "For common words that appear in all documents ('this', 'is', 'the'), the manual TF-IDF score is 0 because their IDF is 0. Scikit-learn's TfidfVectorizer assigns a non-zero (though small) TF-IDF score due to the smoothing term in its IDF formula.\n",
            "The L2 normalization in scikit-learn also scales the scores, making direct comparison of raw values challenging without reproducing the normalization manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4c000e3"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Manual TF scores were very similar to TF scores derived from scikit-learn's `CountVectorizer` (by dividing raw counts by total words), indicating consistent term counting.\n",
        "*   Manual TF-IDF scores differed from scikit-learn's `TfidfVectorizer` scores, particularly for common words.\n",
        "*   The primary reason for the TF-IDF difference is the IDF calculation formula: manual uses $\\text{log}(\\text{Total Documents} / \\text{Document Frequency})$, while scikit-learn uses a smoothed version $\\text{log}((\\text{Total Documents} + 1) / (\\text{Document Frequency} + 1)) + 1$.\n",
        "*   Words appearing in all documents (like 'this', 'is', 'the') have a manual TF-IDF score of 0 because their manual IDF is 0, whereas scikit-learn assigns them a non-zero (though small) score due to smoothing.\n",
        "*   Scikit-learn's `TfidfVectorizer` also applies L2 normalization to the resulting vectors, further contributing to score differences.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Understanding the specific IDF formula and normalization applied by libraries is crucial when comparing manual implementations with library results.\n",
        "*   For practical applications, using optimized and standardized library implementations like scikit-learn is generally preferred over manual implementation due to robustness and efficiency.\n"
      ]
    }
  ]
}